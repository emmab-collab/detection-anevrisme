{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Import from src\n",
    "from src import SERIES_DIR, TRAIN_CSV\n",
    "from src.bricks import Preprocessor, Predictor\n",
    "from src.models import UNet3DClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "print(f\"Loaded {len(df_train)} series from training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pipeline\n",
    "\n",
    "This notebook demonstrates how to use the Predictor class from src.bricks for inference on DICOM series."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Models\n",
    "\n",
    "Load pre-trained models for each modality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load models (update paths to your actual model files)\n",
    "model_dict = {}\n",
    "\n",
    "# Example - adjust paths as needed\n",
    "# model_dict['CTA'] = UNet3DClassifier(in_ch=1, base_ch=32).to(device)\n",
    "# model_dict['CTA'].load_state_dict(torch.load(\"path/to/model_CTA.pth\"))\n",
    "\n",
    "# model_dict['MRA'] = UNet3DClassifier(in_ch=1, base_ch=32).to(device)\n",
    "# model_dict['MRA'].load_state_dict(torch.load(\"path/to/model_MRA.pth\"))\n",
    "\n",
    "print(f\"Loaded {len(model_dict)} models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize Predictor\n",
    "\n",
    "The Predictor class from src.bricks handles the complete inference pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create predictor with loaded models\n",
    "predictor = Predictor(\n",
    "    model_dict=model_dict,\n",
    "    cube_size=(48, 48, 48),\n",
    "    stride=(28, 28, 28),\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"Predictor initialized\")\n",
    "print(predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run Inference on a Single Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: predict on a single series\n",
    "# Get first series from training data\n",
    "import os\n",
    "first_series_uid = df_train['SeriesInstanceUID'].iloc[0]\n",
    "series_path = os.path.join(SERIES_DIR, first_series_uid)\n",
    "\n",
    "if os.path.exists(series_path):\n",
    "    predictions = predictor.predict_series(series_path)\n",
    "    print(f\"Series: {first_series_uid}\")\n",
    "    print(f\"Predictions shape: {predictions.shape}\")\n",
    "    print(f\"Aneurysm probability: {predictions[13]:.4f}\")\n",
    "else:\n",
    "    print(f\"Series not found locally: {series_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Evaluation\n",
    "\n",
    "Evaluate on multiple series and compute metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare evaluation dataset\n",
    "from src.config import ANEURYSM_POSITIONS\n",
    "\n",
    "loc_cols = ANEURYSM_POSITIONS\n",
    "cols_to_keep = ['SeriesInstanceUID'] + loc_cols + ['Aneurysm Present']\n",
    "\n",
    "# Filter to only available local series\n",
    "available_series = [d for d in os.listdir(SERIES_DIR) \n",
    "                   if os.path.isdir(os.path.join(SERIES_DIR, d))]\n",
    "\n",
    "df_eval = df_train[df_train['SeriesInstanceUID'].isin(available_series)][cols_to_keep].copy()\n",
    "\n",
    "print(f\"Available series for evaluation: {len(df_eval)}\")\n",
    "print(f\"With aneurysm: {df_eval['Aneurysm Present'].sum()}\")\n",
    "print(f\"Without aneurysm: {(1 - df_eval['Aneurysm Present']).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run predictions on evaluation set\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for idx, row in tqdm(df_eval.iterrows(), total=len(df_eval), desc=\"Evaluating\"):\n",
    "    series_uid = row['SeriesInstanceUID']\n",
    "    series_path = os.path.join(SERIES_DIR, series_uid)\n",
    "    \n",
    "    try:\n",
    "        predictions = predictor.predict_series(series_path)\n",
    "        y_true.append(row['Aneurysm Present'])\n",
    "        y_pred.append(predictions[13])  # Global aneurysm probability\n",
    "    except Exception as e:\n",
    "        print(f\"Error on {series_uid}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Compute metrics\n",
    "if len(y_true) > 0:\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"  Evaluated: {len(y_true)} series\")\n",
    "    print(f\"  AUC: {auc:.4f}\")\n",
    "else:\n",
    "    print(\"No predictions made\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13851420,
     "sourceId": 99552,
     "sourceType": "competition"
    },
    {
     "datasetId": 8313511,
     "sourceId": 13123808,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 452960,
     "modelInstanceId": 436194,
     "sourceId": 583988,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 454791,
     "modelInstanceId": 438165,
     "sourceId": 586290,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 455167,
     "modelInstanceId": 438590,
     "sourceId": 586774,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 456034,
     "modelInstanceId": 439472,
     "sourceId": 587841,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
