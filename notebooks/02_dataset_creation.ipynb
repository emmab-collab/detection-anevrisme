{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation - CTA/MRA/MRI\n",
    "\n",
    "Ce notebook crée les datasets de cubes 3D pour l'entraînement du modèle.\n",
    "\n",
    "**Étapes** :\n",
    "1. Chargement des données localisateurs\n",
    "2. Filtrage par modalité (CTA, MRA, MRI T1post, MRI T2)\n",
    "3. Vérification de la disponibilité des données\n",
    "4. Test sur un exemple\n",
    "5. Extraction de cubes positifs (contenant anévrisme) et négatifs\n",
    "6. Sauvegarde au format .npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import du package src\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src import (\n",
    "    SERIES_DIR,\n",
    "    TRAIN_CSV,\n",
    "    TRAIN_LOCALIZERS_CSV,\n",
    "    PROCESSED_DIR,\n",
    "    print_config\n",
    ")\n",
    "from src.data import ajouter_Modality\n",
    "from src.preprocessing import preprocessing_volume_and_coords\n",
    "from src.visualization import show_middle_slices, show_slice_with_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration et chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de la configuration automatique\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement DataFrames (chemins automatiques)\n",
    "df_loc = pd.read_csv(TRAIN_LOCALIZERS_CSV)\n",
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "# Ajout modalité\n",
    "df_loc = ajouter_Modality(df_loc, df_train)\n",
    "\n",
    "print(f\"Total localizers: {len(df_loc)}\")\n",
    "print(f\"\\nModalités:\")\n",
    "print(df_loc['Modality'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filtrage par modalité\n",
    "\n",
    "Choisissez la modalité à traiter (CTA, MRA, MRI T1post, MRI T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection modalité\n",
    "MODALITY = \"CTA\"  # Changez selon besoin: \"CTA\", \"MRA\", \"MRI T1post\", \"MRI T2\"\n",
    "\n",
    "df_modality = df_loc[df_loc['Modality'] == MODALITY].reset_index(drop=True)\n",
    "print(f\"Nombre de {MODALITY}: {len(df_modality)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vérification de la disponibilité des données\n",
    "\n",
    "Avant de traiter les données, vérifions quels patients sont réellement disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier combien de patients de la modalité sont disponibles localement\n",
    "available_patients = []\n",
    "for i in range(len(df_modality)):\n",
    "    series_uid = df_modality.iloc[i]['SeriesInstanceUID']\n",
    "    patient_path = os.path.join(SERIES_DIR, series_uid)\n",
    "    if os.path.exists(patient_path):\n",
    "        available_patients.append(series_uid)\n",
    "\n",
    "print(f\"Patients {MODALITY} dans le CSV: {len(df_modality)}\")\n",
    "print(f\"Patients {MODALITY} disponibles localement: {len(available_patients)}\")\n",
    "\n",
    "if len(available_patients) > 0:\n",
    "    print(f\"\\n✓ {len(available_patients)} patients prêts pour le traitement\")\n",
    "else:\n",
    "    print(f\"\\n⚠️ Aucun patient disponible localement\")\n",
    "    print(f\"Les données DICOM doivent être téléchargées dans: {SERIES_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test sur un exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sur le premier patient disponible\n",
    "if len(available_patients) > 0:\n",
    "    # Utiliser le premier patient disponible identifié à l'étape 3\n",
    "    series_uid = available_patients[0]\n",
    "    patient_path = os.path.join(SERIES_DIR, series_uid)\n",
    "    \n",
    "    print(f\"Patient sélectionné: {series_uid}\")\n",
    "    \n",
    "    try:\n",
    "        volume, aneurysm_coords = preprocessing_volume_and_coords(\n",
    "            SERIES_DIR, patient_path, df_modality\n",
    "        )\n",
    "        \n",
    "        print(f\"Volume shape: {volume.shape}\")\n",
    "        print(f\"Aneurysm coordinates: {aneurysm_coords}\")\n",
    "        \n",
    "        # Visualisation\n",
    "        show_middle_slices(volume)\n",
    "        show_slice_with_point(volume, aneurysm_coords, plane=\"axial\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du traitement: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(f\"⚠️ Aucun patient {MODALITY} disponible localement\")\n",
    "    print(f\"Exécutez d'abord l'étape 3 pour vérifier les données disponibles.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Création du dataset\n",
    "\n",
    "**Note**: Les fonctions `extract_positives_cubes`, `extract_negative_cubes`, et `build_dataset_dict` \n",
    "doivent être ajoutées au package `src/` si elles ne le sont pas déjà."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implémenter la création du dataset\n",
    "# Exemple de structure attendue:\n",
    "\n",
    "# dataset = {\n",
    "#     'patient_0': {\n",
    "#         'patient_ID': [...],\n",
    "#         'cubes': [...],  # array (N, 48, 48, 48)\n",
    "#         'labels': [...],  # array (N,)\n",
    "#         'positions': [...]  # array (N, 13)\n",
    "#     },\n",
    "#     ...\n",
    "# }\n",
    "\n",
    "print(\"Dataset creation: À implémenter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sauvegarde du dataset (utilise PROCESSED_DIR automatiquement)\n",
    "# output_path = os.path.join(PROCESSED_DIR, f\"{MODALITY}_dataset.npz\")\n",
    "# np.savez(output_path, **dataset)\n",
    "# print(f\"Dataset sauvegardé: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
