{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation - CTA/MRA/MRI\n",
    "\n",
    "Ce notebook crée les datasets de cubes 3D pour l'entraînement du modèle.\n",
    "\n",
    "**Étapes** :\n",
    "1. Chargement des données localisateurs\n",
    "2. Filtrage par modalité (CTA, MRA, MRI T1post, MRI T2)\n",
    "3. Extraction de cubes positifs (contenant anévrisme) et négatifs\n",
    "4. Sauvegarde au format .npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import du package src\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src import (\n",
    "    SERIES_DIR,\n",
    "    TRAIN_CSV,\n",
    "    TRAIN_LOCALIZERS_CSV,\n",
    "    PROCESSED_DIR,\n",
    "    print_config\n",
    ")\n",
    "from src.data import ajouter_Modality\n",
    "from src.preprocessing import preprocessing_volume_and_coords\n",
    "from src.visualization import show_middle_slices, show_slice_with_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration et chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de la configuration automatique\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement DataFrames (chemins automatiques)\n",
    "df_loc = pd.read_csv(TRAIN_LOCALIZERS_CSV)\n",
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "# Ajout modalité\n",
    "df_loc = ajouter_Modality(df_loc, df_train)\n",
    "\n",
    "print(f\"Total localizers: {len(df_loc)}\")\n",
    "print(f\"\\nModalités:\")\n",
    "print(df_loc['Modality'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filtrage par modalité\n",
    "\n",
    "Choisissez la modalité à traiter (CTA, MRA, MRI T1post, MRI T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection modalité\n",
    "MODALITY = \"CTA\"  # Changez selon besoin: \"CTA\", \"MRA\", \"MRI T1post\", \"MRI T2\"\n",
    "\n",
    "df_modality = df_loc[df_loc['Modality'] == MODALITY].reset_index(drop=True)\n",
    "print(f\"Nombre de {MODALITY}: {len(df_modality)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test sur un exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sur le premier patient\n",
    "if len(df_modality) > 0:\n",
    "    i = 0\n",
    "    patient_path = os.path.join(SERIES_DIR, df_modality.iloc[i]['SeriesInstanceUID'])\n",
    "    \n",
    "    try:\n",
    "        volume, aneurysm_coords = preprocessing_volume_and_coords(\n",
    "            SERIES_DIR, patient_path, df_modality\n",
    "        )\n",
    "        \n",
    "        print(f\"Volume shape: {volume.shape}\")\n",
    "        print(f\"Aneurysm coordinates: {aneurysm_coords}\")\n",
    "        \n",
    "        # Visualisation\n",
    "        show_middle_slices(volume)\n",
    "        show_slice_with_point(volume, aneurysm_coords, plane=\"axial\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur: {e}\")\n",
    "else:\n",
    "    print(f\"Aucune série {MODALITY} trouvée dans vos données locales.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Création du dataset\n",
    "\n",
    "**Note**: Les fonctions `extract_positives_cubes`, `extract_negative_cubes`, et `build_dataset_dict` \n",
    "doivent être ajoutées au package `src/` si elles ne le sont pas déjà."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implémenter la création du dataset\n",
    "# Exemple de structure attendue:\n",
    "\n",
    "# dataset = {\n",
    "#     'patient_0': {\n",
    "#         'patient_ID': [...],\n",
    "#         'cubes': [...],  # array (N, 48, 48, 48)\n",
    "#         'labels': [...],  # array (N,)\n",
    "#         'positions': [...]  # array (N, 13)\n",
    "#     },\n",
    "#     ...\n",
    "# }\n",
    "\n",
    "print(\"Dataset creation: À implémenter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sauvegarde du dataset (utilise PROCESSED_DIR automatiquement)\n",
    "# output_path = os.path.join(PROCESSED_DIR, f\"{MODALITY}_dataset.npz\")\n",
    "# np.savez(output_path, **dataset)\n",
    "# print(f\"Dataset sauvegardé: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
