# Notebooks - Aneurysm Detection

Ce dossier contient les notebooks Jupyter pour l'analyse et le dÃ©veloppement du projet de dÃ©tection d'anÃ©vrismes.

## ğŸ“‹ Vue d'ensemble

Les notebooks sont organisÃ©s par Ã©tapes du workflow de machine learning, de l'exploration des donnÃ©es jusqu'Ã  l'infÃ©rence.

## ğŸ“š Liste des notebooks

### [01_exploration_donnees.ipynb](01_exploration_donnees.ipynb)
**Objectif** : Exploration et nettoyage des donnÃ©es DICOM

**Contenu** :
- Chargement des datasets (train.csv, train_localizers.csv)
- Analyse des modalitÃ©s (CTA, MRA, MRI T1post, MRI T2)
- DÃ©tection et filtrage des sÃ©ries dÃ©fectueuses
- Statistiques sur les dimensions des volumes
- Visualisation des distributions

**Sorties** : df_cleaned.csv avec les sÃ©ries valides

---

### [02_dataset_creation.ipynb](02_dataset_creation.ipynb)
**Objectif** : CrÃ©ation des datasets de cubes 3D

**Contenu** :
- Extraction de cubes positifs (contenant anÃ©vrismes)
- Extraction de cubes nÃ©gatifs (sans anÃ©vrismes)
- CrÃ©ation de dictionnaires par modalitÃ©
- Sauvegarde au format .npz

**Sorties** : CTA_dataset.npz, MRA_dataset.npz, etc.

---

### [03_entrainement_modele.ipynb](03_entrainement_modele.ipynb)
**Objectif** : EntraÃ®nement du modÃ¨le U-Net 3D

**Contenu** :
- Chargement des datasets
- DÃ©finition du modÃ¨le U-Net 3D
- Configuration de l'entraÃ®nement (optimizer, loss, metrics)
- EntraÃ®nement avec validation
- Sauvegarde des checkpoints

**Sorties** : best_model.pth, courbes de loss/accuracy

---

### [04_inference.ipynb](04_inference.ipynb)
**Objectif** : Pipeline d'infÃ©rence complet

**Contenu** :
- Chargement du modÃ¨le entraÃ®nÃ©
- PrÃ©processing d'une nouvelle sÃ©rie DICOM
- Extraction de cubes chevauchants
- PrÃ©diction et agrÃ©gation
- Calcul des mÃ©triques (AUC, accuracy)

**Sorties** : PrÃ©dictions pour le test set

---

### [05_data_augmentation.ipynb](05_data_augmentation.ipynb)
**Objectif** : Augmentation de donnÃ©es par dÃ©formations Ã©lastiques

**Contenu** :
- Application de dÃ©formations alÃ©atoires 3D
- GÃ©nÃ©ration de multiples versions augmentÃ©es
- Visualisation des transformations
- Sauvegarde des datasets augmentÃ©s

**Sorties** : cubes_augmented.npy

---

### [06_gestion_erreurs.ipynb](06_gestion_erreurs.ipynb)
**Objectif** : Analyse des erreurs et extraction de hard negatives

**Contenu** :
- DÃ©tection des faux positifs/faux nÃ©gatifs
- Analyse des cas difficiles
- Extraction de hard negatives pour rÃ©entraÃ®nement
- Visualisation des erreurs du modÃ¨le

**Sorties** : hard_negatives.npy

---

## ğŸš€ Ordre d'exÃ©cution recommandÃ©

```
01 â†’ 02 â†’ 05 â†’ 03 â†’ 06 â†’ 04
 â†“     â†“    â†“    â†“    â†“    â†“
EDA  Data  Aug  Train Error Infer
```

1. **01_exploration_donnees** - Comprendre les donnÃ©es
2. **02_dataset_creation** - CrÃ©er les cubes
3. **05_data_augmentation** - Augmenter le dataset
4. **03_entrainement_modele** - EntraÃ®ner le modÃ¨le
5. **06_gestion_erreurs** - Analyser les erreurs
6. **04_inference** - Faire des prÃ©dictions

## ğŸ’» Configuration requise

### Imports du package `src/`

Tous les notebooks utilisent le package `src/` du projet :

```python
import sys
sys.path.append("../")

from src.data import dicom_to_numpy, ajouter_Modality
from src.preprocessing import preprocessing_volume, resample, crop
from src.visualization import show_middle_slices
from src.augmentation import data_augmentation
```

### Installation des dÃ©pendances

```bash
pip install -r ../requirements.txt
```

### Structure attendue

```
ANEURYSM DETECTION/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ train_localizers.csv
â”‚   â””â”€â”€ series/
â”œâ”€â”€ notebooks/          # â† Vous Ãªtes ici
â”œâ”€â”€ src/                # Package Python
â””â”€â”€ results/
```

## ğŸ“ Notes importantes

### Nettoyage des outputs

Les notebooks peuvent contenir de gros outputs (images, arrays). Pour nettoyer :

```bash
# Installer nbstripout
pip install nbstripout

# Configurer pour nettoyer automatiquement
nbstripout --install

# Nettoyer manuellement
jupyter nbconvert --clear-output --inplace *.ipynb
```

### Chemins des donnÃ©es

Les chemins sont configurables en dÃ©but de chaque notebook. Adaptez selon votre environnement :

```python
# Local
DATA_DIR = "../data"

# Kaggle
DATA_DIR = "/kaggle/input/rsna-intracranial-aneurysm-detection"
```

## ğŸ› Troubleshooting

**Import Error du package src/** :
```python
# VÃ©rifiez le chemin
import sys
print(sys.path)
sys.path.append("../")  # ou chemin absolu
```

**Erreur PixelSpacing** :
- Certains fichiers DICOM n'ont pas de PixelSpacing
- Utiliser un try/except ou filtrer au prÃ©alable

**MÃ©moire insuffisante** :
- RÃ©duire le batch_size
- Traiter les donnÃ©es par lots
- Utiliser un subset pour les tests

## ğŸ“§ Contact

Pour toute question sur les notebooks, consultez la documentation du package `src/` ou ouvrez une issue.
