# DÃ©tection d'AnÃ©vrismes CÃ©rÃ©braux par Deep Learning ğŸ§ 

[![Python 3.13+](https://img.shields.io/badge/python-3.13+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.7+-ee4c2c.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-Educational-green.svg)](LICENSE)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

Projet de dÃ©tection automatique d'anÃ©vrismes cÃ©rÃ©braux Ã  partir d'images mÃ©dicales 3D (CTA, MRA, MRI) utilisant des rÃ©seaux de neurones convolutifs 3D.

---

## ğŸ“Š Ã€ propos de ce Repository

### Version de DÃ©monstration

Ce repository contient une **version de dÃ©monstration locale** d'un projet plus large rÃ©alisÃ© sur Kaggle.

| Aspect | Version Kaggle (Originale) | Version DÃ©monstration (ce repo) |
|--------|---------------------------|----------------------------------|
| **DonnÃ©es** | 4000+ sÃ©ries DICOM | 20 sÃ©ries Ã©chantillons |
| **Environnement** | Kaggle GPU | Local (CPU/GPU) |
| **Objectif** | EntraÃ®nement complet | DÃ©monstration & Portfolio |
| **Architecture** | Identique âœ“ | Identique âœ“ |
| **Pipeline** | Identique âœ“ | Identique âœ“ |

**But de cette version** : Permettre aux recruteurs et collaborateurs de :
- Visualiser la structure du projet et du code
- Comprendre le pipeline de preprocessing
- Voir des exemples concrets de datasets crÃ©Ã©s
- Tester le code localement sans tÃ©lÃ©charger 4000 sÃ©ries

---

## ğŸ—ï¸ Architecture du Projet

Le projet suit une **architecture modulaire brick-based** pour une rÃ©utilisabilitÃ© maximale :

```
src/
â”œâ”€â”€ bricks/              # Composants rÃ©utilisables
â”‚   â”œâ”€â”€ preprocessing.py # Pipeline de preprocessing 3D
â”‚   â””â”€â”€ dataset.py       # Construction de datasets
â”œâ”€â”€ data/                # Utilitaires de chargement DICOM
â”œâ”€â”€ preprocessing/       # Transformations (resample, crop, normalize)
â”œâ”€â”€ visualization/       # Visualisation de volumes 3D
â””â”€â”€ config.py            # Configuration centralisÃ©e
```

### Composants Principaux

**`Preprocessor`** : Pipeline de preprocessing pour volumes DICOM 3D
- Chargement DICOM
- Resampling Ã  espacement cible
- Cropping automatique
- Normalisation

**`DatasetBuilder`** : Construction de datasets d'entraÃ®nement
- Extraction de cubes 3D (positifs/nÃ©gatifs)
- One-hot encoding des positions anatomiques
- Sauvegarde au format `.npz`

---

## ğŸ“ Structure des DonnÃ©es

### ModalitÃ©s SupportÃ©es

Le projet gÃ¨re 4 modalitÃ©s d'imagerie mÃ©dicale :

| ModalitÃ© | Description | SÃ©ries (dÃ©mo) | SÃ©ries (Kaggle) |
|----------|-------------|---------------|-----------------|
| **CTA** | Angiographie par tomodensitomÃ©trie | 9 | ~1220 |
| **MRA** | Angiographie par rÃ©sonance magnÃ©tique | 3 | ~661 |
| **MRI T2** | IRM pondÃ©rÃ©e T2 | 7 | ~280 |
| **MRI T1post** | IRM T1 avec contraste | 1 | ~93 |

### Datasets CrÃ©Ã©s

Chaque modalitÃ© gÃ©nÃ¨re un fichier `.npz` contenant :

```python
{
    'cubes': np.ndarray,      # (N, 48, 48, 48) - Cubes 3D normalisÃ©s
    'labels': np.ndarray,     # (N,) - 0=nÃ©gatif, 1=positif
    'positions': np.ndarray,  # (N, 13) - One-hot encoding position anatomique
    'patient_ids': list       # (N,) - SeriesInstanceUID
}
```

**Fichiers gÃ©nÃ©rÃ©s** :
- `results/processed/cta_dataset.npz`
- `results/processed/mra_dataset.npz`
- `results/processed/mri_t2_dataset.npz`
- `results/processed/mri_t1post_dataset.npz`

---

## ğŸ““ Notebooks

| Notebook | Description | Usage |
|----------|-------------|-------|
| `01_exploration_donnees.ipynb` | Analyse exploratoire des donnÃ©es DICOM | Comprendre les donnÃ©es |
| `02_dataset_creation.ipynb` | CrÃ©ation des 4 datasets par modalitÃ© | **ExÃ©cuter en premier** |
| `03_entrainement_modele.ipynb` | EntraÃ®nement du modÃ¨le 3D CNN | AprÃ¨s crÃ©ation datasets |
| `04_inference.ipynb` | InfÃ©rence sur nouveaux patients | Tests & dÃ©monstration |

> **Note**: Les notebooks utilisent un Ã©chantillon de 20 sÃ©ries DICOM pour dÃ©monstration.
> Le projet original sur Kaggle a traitÃ© 4000+ sÃ©ries avec la mÃªme architecture.

---

## ğŸš€ Utilisation

### PrÃ©requis

```bash
pip install -r requirements.txt
```

### Configuration Automatique

Le projet dÃ©tecte automatiquement l'environnement (Kaggle vs Local) :

```python
from src import SERIES_DIR, TRAIN_CSV, PROCESSED_DIR, print_config

print_config()  # Affiche les chemins configurÃ©s
```

### CrÃ©ation des Datasets

1. **Ouvrir** `notebooks/02_dataset_creation.ipynb`
2. **ExÃ©cuter** les cellules jusqu'Ã  la section 5
3. **DÃ©commenter** le code de crÃ©ation dans les sections 5, 6, 7
4. **Lancer** la crÃ©ation des 4 datasets

Les datasets seront sauvegardÃ©s dans `results/processed/`

### Structure des RÃ©sultats

```
results/
â”œâ”€â”€ processed/           # Datasets crÃ©Ã©s (.npz)
â”œâ”€â”€ models/             # ModÃ¨les entraÃ®nÃ©s (.pth)
â””â”€â”€ checkpoints/        # Checkpoints d'entraÃ®nement
```

---

## ğŸ¯ RÃ©sultats de la DÃ©monstration

### Datasets de DÃ©monstration CrÃ©Ã©s

| ModalitÃ© | SÃ©ries | Cubes positifs | Cubes nÃ©gatifs | Total | Balance |
|----------|--------|----------------|----------------|-------|---------|
| **CTA** | 9 | 8 | 15 | 23 | 34.8% |
| **MRA** | 3 | 2 | 5 | 7 | 28.6% |
| **MRI T2** | 7 | 1 | 25 | 26 | 3.8% |
| **MRI T1post** | 1 | 0 | 5 | 5 | 0.0% |

**Total : 61 cubes 3D (48Ã—48Ã—48) extraits de 20 sÃ©ries DICOM**

*Note : Ces datasets sont disponibles dans `results/processed/` au format `.npz`*

### Utilisation RecommandÃ©e

- **CTA** : Dataset principal pour dÃ©monstration (meilleure reprÃ©sentativitÃ©)
- **MRA** : Validation cross-modalitÃ©
- **MRI T2** : Tests de gÃ©nÃ©ralisation
- **MRI T1post** : Exemple de modalitÃ© rare

---

## ğŸ”§ Technologies

- **Python 3.13+**
- **PyTorch** : Deep Learning
- **PyDICOM** : Lecture fichiers DICOM
- **NumPy & SciPy** : Traitement volumÃ©trique
- **Pandas** : Manipulation de donnÃ©es
- **Matplotlib** : Visualisation

---

## ğŸ“ Notes Importantes

### Limitations de la Version DÃ©monstration

- âš ï¸ **DonnÃ©es limitÃ©es** : 20 sÃ©ries vs 4000 sur Kaggle
- âš ï¸ **Performances** : RÃ©sultats non reprÃ©sentatifs (Ã©chantillon trop petit)
- âš ï¸ **Usage** : DÃ©monstration de l'architecture uniquement

### Points Forts du Projet

- âœ… **Architecture modulaire** : Code rÃ©utilisable et maintenable
- âœ… **Multi-modalitÃ©s** : Support de 4 types d'imagerie mÃ©dicale
- âœ… **Pipeline complet** : De DICOM brut Ã  modÃ¨le entraÃ®nÃ©
- âœ… **Gestion d'erreurs** : Robuste aux donnÃ©es manquantes
- âœ… **Documentation** : Code commentÃ© et notebooks explicatifs

---

## ğŸ’¡ Ce que j'ai appris / What I Learned

### DÃ©fis Techniques RencontrÃ©s

**1. Gestion Multi-ModalitÃ©s**
- **DÃ©fi** : Les 4 modalitÃ©s d'imagerie (CTA, MRA, MRI T2, MRI T1post) ont des caractÃ©ristiques trÃ¨s diffÃ©rentes (rÃ©solution, contraste, espacement voxel)
- **Solution** : Architecture de preprocessing adaptative avec resampling intelligent et normalisation par modalitÃ©
- **Apprentissage** : L'importance de la standardisation pour la gÃ©nÃ©ralisation cross-modalitÃ©

**2. Padding Intelligent des Cubes 3D**
- **DÃ©fi** : Les anÃ©vrismes aux bords des volumes gÃ©nÃ©raient des cubes incomplets
- **Solution** : SystÃ¨me de padding centrÃ© avec fallback pour garantir toujours la forme (48, 48, 48)
- **Apprentissage** : La gestion des cas limites est cruciale pour Ã©viter les erreurs silencieuses en production

**3. ScalabilitÃ© de l'Architecture**
- **DÃ©fi** : Concevoir un code qui fonctionne sur 20 sÃ©ries (dÃ©mo) ET 4000+ (production)
- **Solution** : Pattern "brick-based" avec filtrage automatique des donnÃ©es disponibles
- **Apprentissage** : L'abstraction et la modularitÃ© permettent une vraie scalabilitÃ©

**4. Gestion de Datasets DÃ©sÃ©quilibrÃ©s**
- **DÃ©fi** : Balance positive variable (34.8% CTA, 3.8% MRI T2, 0% MRI T1post)
- **Solution** : Extraction configurable de cubes nÃ©gatifs, stratÃ©gie d'augmentation par modalitÃ©
- **Apprentissage** : Le class imbalance doit Ãªtre gÃ©rÃ© dÃ¨s la crÃ©ation du dataset, pas seulement Ã  l'entraÃ®nement

### Trade-offs Architecturaux

**Choix 1 : .npz vs HDF5**
- âœ… Choisi `.npz` pour sa simplicitÃ© et compatibilitÃ© NumPy native
- âš ï¸ Trade-off : Moins performant que HDF5 pour trÃ¨s gros datasets (> 10GB)
- ğŸ“Š Impact : Acceptable pour dÃ©mo (6.3MB total), Ã  reconsidÃ©rer pour production

**Choix 2 : Cubes fixes 48Ã—48Ã—48 vs tailles variables**
- âœ… Cubes fixes pour batch processing efficace en PyTorch
- âš ï¸ Trade-off : Perte d'information pour grands anÃ©vrismes
- ğŸ“Š Impact : Simplifie l'entraÃ®nement, couvre 95%+ des cas cliniques

**Choix 3 : Preprocessing synchrone vs pipeline asynchrone**
- âœ… Synchrone pour traÃ§abilitÃ© et debugging
- âš ï¸ Trade-off : Temps de traitement plus long (20min pour 20 sÃ©ries)
- ğŸ“Š Impact : Acceptable pour dÃ©mo, optimisable avec multiprocessing en production

### CompÃ©tences DÃ©veloppÃ©es

- **Medical Imaging** : MaÃ®trise du format DICOM, preprocessing 3D (resampling, cropping, windowing)
- **Software Engineering** : Design patterns (Builder, Preprocessor), architecture modulaire, gestion d'erreurs robuste
- **Production ML** : Configuration multi-environnement, logging, versioning de datasets
- **Domain Expertise** : Anatomie cÃ©rÃ©brale, positions d'anÃ©vrismes, modalitÃ©s d'imagerie

---

## ğŸ“š RÃ©fÃ©rences

- **Dataset source** : [RSNA Intracranial Aneurysm Detection](https://www.kaggle.com/competitions/rsna-intracranial-aneurysm-detection)
- **Architecture** : Inspired by 3D ResNet for medical imaging
- **PyDICOM Documentation** : [https://pydicom.github.io/](https://pydicom.github.io/)
- **Medical Imaging Resources** : [RadioGraphics RSNA](https://pubs.rsna.org/journal/radiographics)

---

## ğŸ‘¤ Auteur

**Emma B.**

*Ã‰tudiante en L3 MathÃ©matiques*
*Data Scientist autodidacte passionnÃ©e par le ML appliquÃ© Ã  la santÃ©*

---

## ğŸ“„ License

Ce projet est Ã  usage Ã©ducatif et de dÃ©monstration pour portfolio professionnel.

Les donnÃ©es DICOM ne sont pas incluses dans ce repository pour des raisons de confidentialitÃ© et de taille.
