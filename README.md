# D√©tection d'An√©vrismes C√©r√©braux par Deep Learning

[![Python 3.13+](https://img.shields.io/badge/python-3.13+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.7+-ee4c2c.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-Educational-green.svg)](LICENSE)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

Projet de d√©tection automatique d'an√©vrismes c√©r√©braux √† partir d'images m√©dicales 3D (CTA, MRA, MRI) utilisant des r√©seaux de neurones convolutifs 3D.

---

## √Ä propos de ce Repository

### Version de D√©monstration

Ce repository contient une **version de d√©monstration locale** d'un projet plus large r√©alis√© sur Kaggle.

| Aspect | Version Kaggle (Originale) | Version D√©monstration (ce repo) |
|--------|---------------------------|----------------------------------|
| **Donn√©es** | 4000+ s√©ries DICOM | 20 s√©ries √©chantillons |
| **Environnement** | Kaggle GPU | Local (CPU/GPU) |
| **Objectif** | Entra√Ænement complet | D√©monstration & Portfolio |
| **Architecture** | Identique ‚úì | Identique ‚úì |
| **Pipeline** | Identique ‚úì | Identique ‚úì |

**But de cette version** : Permettre aux recruteurs et collaborateurs de :
- Visualiser la structure du projet et du code
- Comprendre le pipeline de preprocessing
- Voir des exemples concrets de datasets cr√©√©s
- Tester le code localement sans t√©l√©charger 4000 s√©ries

---

## Architecture du Projet

Le projet suit une **architecture modulaire brick-based** pour une r√©utilisabilit√© maximale :

```
src/
‚îú‚îÄ‚îÄ bricks/              # Composants r√©utilisables
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py # Pipeline de preprocessing 3D
‚îÇ   ‚îî‚îÄ‚îÄ dataset.py       # Construction de datasets
‚îú‚îÄ‚îÄ data/                # Utilitaires de chargement DICOM
‚îú‚îÄ‚îÄ preprocessing/       # Transformations (resample, crop, normalize)
‚îú‚îÄ‚îÄ visualization/       # Visualisation de volumes 3D
‚îî‚îÄ‚îÄ config.py            # Configuration centralis√©e
```

### Composants Principaux

**`Preprocessor`** : Pipeline de preprocessing pour volumes DICOM 3D
- Chargement DICOM
- Resampling √† espacement cible
- Cropping automatique
- Normalisation

**`DatasetBuilder`** : Construction de datasets d'entra√Ænement
- Extraction de cubes 3D (positifs/n√©gatifs)
- One-hot encoding des positions anatomiques
- Sauvegarde au format `.npz`

---

## Structure des Donn√©es

### Modalit√©s Support√©es

Le projet g√®re 4 modalit√©s d'imagerie m√©dicale :

| Modalit√© | Description | S√©ries (d√©mo) | S√©ries (Kaggle) |
|----------|-------------|---------------|-----------------|
| **CTA** | Angiographie par tomodensitom√©trie | 9 | ~1220 |
| **MRA** | Angiographie par r√©sonance magn√©tique | 3 | ~661 |
| **MRI T2** | IRM pond√©r√©e T2 | 7 | ~280 |
| **MRI T1post** | IRM T1 avec contraste | 1 | ~93 |

### Datasets Cr√©√©s

Chaque modalit√© g√©n√®re un fichier `.npz` contenant :

```python
{
    'cubes': np.ndarray,      # (N, 48, 48, 48) - Cubes 3D normalis√©s
    'labels': np.ndarray,     # (N,) - 0=n√©gatif, 1=positif
    'positions': np.ndarray,  # (N, 13) - One-hot encoding position anatomique
    'patient_ids': list       # (N,) - SeriesInstanceUID
}
```

**Fichiers g√©n√©r√©s** :
- `results/processed/cta_dataset.npz`
- `results/processed/mra_dataset.npz`
- `results/processed/mri_t2_dataset.npz`
- `results/processed/mri_t1post_dataset.npz`

---

## Notebooks

| Notebook | Description | Usage |
|----------|-------------|-------|
| `01_exploration_donnees.ipynb` | Analyse exploratoire des donn√©es DICOM | Comprendre les donn√©es |
| `02_dataset_creation.ipynb` | Cr√©ation des 4 datasets par modalit√© | **Ex√©cuter en premier** |
| `03_entrainement_modele.ipynb` | Entra√Ænement du mod√®le 3D CNN | Apr√®s cr√©ation datasets |
| `04_inference.ipynb` | Inf√©rence sur nouveaux patients | Tests & d√©monstration |

> **Note**: Les notebooks utilisent un √©chantillon de 20 s√©ries DICOM pour d√©monstration.
> Le projet original sur Kaggle a trait√© 4000+ s√©ries avec la m√™me architecture.

---

## Utilisation

### Pr√©requis

```bash
pip install -r requirements.txt
```

### Configuration Automatique

Le projet d√©tecte automatiquement l'environnement (Kaggle vs Local) :

```python
from src import SERIES_DIR, TRAIN_CSV, PROCESSED_DIR, print_config

print_config()  # Affiche les chemins configur√©s
```

### Cr√©ation des Datasets

1. **Ouvrir** `notebooks/02_dataset_creation.ipynb`
2. **Ex√©cuter** les cellules jusqu'√† la section 5
3. **D√©commenter** le code de cr√©ation dans les sections 5, 6, 7
4. **Lancer** la cr√©ation des 4 datasets

Les datasets seront sauvegard√©s dans `results/processed/`

### Structure des R√©sultats

```
results/
‚îú‚îÄ‚îÄ processed/           # Datasets cr√©√©s (.npz)
‚îú‚îÄ‚îÄ models/             # Mod√®les entra√Æn√©s (.pth)
‚îî‚îÄ‚îÄ checkpoints/        # Checkpoints d'entra√Ænement
```

---

## R√©sultats de la D√©monstration

### Datasets de D√©monstration Cr√©√©s

| Modalit√© | S√©ries | Cubes positifs | Cubes n√©gatifs | Total | Balance |
|----------|--------|----------------|----------------|-------|---------|
| **CTA** | 9 | 8 | 15 | 23 | 34.8% |
| **MRA** | 3 | 2 | 5 | 7 | 28.6% |
| **MRI T2** | 7 | 1 | 25 | 26 | 3.8% |
| **MRI T1post** | 1 | 0 | 5 | 5 | 0.0% |

**Total : 61 cubes 3D (48√ó48√ó48) extraits de 20 s√©ries DICOM**

*Note : Ces datasets sont disponibles dans `results/processed/` au format `.npz`*

### Utilisation Recommand√©e

- **CTA** : Dataset principal pour d√©monstration (meilleure repr√©sentativit√©)
- **MRA** : Validation cross-modalit√©
- **MRI T2** : Tests de g√©n√©ralisation
- **MRI T1post** : Exemple de modalit√© rare

---

## Technologies

- **Python 3.13+**
- **PyTorch** : Deep Learning
- **PyDICOM** : Lecture fichiers DICOM
- **NumPy & SciPy** : Traitement volum√©trique
- **Pandas** : Manipulation de donn√©es
- **Matplotlib** : Visualisation

---

## Notes Importantes

### Limitations de la Version D√©monstration

- ‚ö†Ô∏è **Donn√©es limit√©es** : 20 s√©ries vs 4000 sur Kaggle
- ‚ö†Ô∏è **Performances** : R√©sultats non repr√©sentatifs (√©chantillon trop petit)
- ‚ö†Ô∏è **Usage** : D√©monstration de l'architecture uniquement

### Points Forts du Projet

- ‚úÖ **Architecture modulaire** : Code r√©utilisable et maintenable
- ‚úÖ **Multi-modalit√©s** : Support de 4 types d'imagerie m√©dicale
- ‚úÖ **Pipeline complet** : De DICOM brut √† mod√®le entra√Æn√©
- ‚úÖ **Gestion d'erreurs** : Robuste aux donn√©es manquantes
- ‚úÖ **Documentation** : Code comment√© et notebooks explicatifs

---

## Ce que j'ai appris / What I Learned

### D√©fis Techniques Rencontr√©s

**1. Gestion Multi-Modalit√©s**
- **D√©fi** : Les 4 modalit√©s d'imagerie (CTA, MRA, MRI T2, MRI T1post) ont des caract√©ristiques tr√®s diff√©rentes (r√©solution, contraste, espacement voxel)
- **Solution** : Architecture de preprocessing adaptative avec resampling intelligent et normalisation par modalit√©
- **Apprentissage** : L'importance de la standardisation pour la g√©n√©ralisation cross-modalit√©

**2. Padding Intelligent des Cubes 3D**
- **D√©fi** : Les an√©vrismes aux bords des volumes g√©n√©raient des cubes incomplets
- **Solution** : Syst√®me de padding centr√© avec fallback pour garantir toujours la forme (48, 48, 48)
- **Apprentissage** : La gestion des cas limites est cruciale pour √©viter les erreurs silencieuses en production

**3. Scalabilit√© de l'Architecture**
- **D√©fi** : Concevoir un code qui fonctionne sur 20 s√©ries (d√©mo) ET 4000+ (production)
- **Solution** : Pattern "brick-based" avec filtrage automatique des donn√©es disponibles
- **Apprentissage** : L'abstraction et la modularit√© permettent une vraie scalabilit√©

**4. Gestion de Datasets D√©s√©quilibr√©s**
- **D√©fi** : Balance positive variable (34.8% CTA, 3.8% MRI T2, 0% MRI T1post)
- **Solution** : Extraction configurable de cubes n√©gatifs, strat√©gie d'augmentation par modalit√©
- **Apprentissage** : Le class imbalance doit √™tre g√©r√© d√®s la cr√©ation du dataset, pas seulement √† l'entra√Ænement

### Trade-offs Architecturaux

**Choix 1 : .npz vs HDF5**
- ‚úÖ Choisi `.npz` pour sa simplicit√© et compatibilit√© NumPy native
- ‚ö†Ô∏è Trade-off : Moins performant que HDF5 pour tr√®s gros datasets (> 10GB)
- üìä Impact : Acceptable pour d√©mo (6.3MB total), √† reconsid√©rer pour production

**Choix 2 : Cubes fixes 48√ó48√ó48 vs tailles variables**
- ‚úÖ Cubes fixes pour batch processing efficace en PyTorch
- ‚ö†Ô∏è Trade-off : Perte d'information pour grands an√©vrismes
- üìä Impact : Simplifie l'entra√Ænement, couvre 95%+ des cas cliniques

**Choix 3 : Preprocessing synchrone vs pipeline asynchrone**
- ‚úÖ Synchrone pour tra√ßabilit√© et debugging
- ‚ö†Ô∏è Trade-off : Temps de traitement plus long (20min pour 20 s√©ries)
- üìä Impact : Acceptable pour d√©mo, optimisable avec multiprocessing en production

### Comp√©tences D√©velopp√©es

- **Medical Imaging** : Ma√Ætrise du format DICOM, preprocessing 3D (resampling, cropping, windowing)
- **Software Engineering** : Design patterns (Builder, Preprocessor), architecture modulaire, gestion d'erreurs robuste
- **Production ML** : Configuration multi-environnement, logging, versioning de datasets
- **Domain Expertise** : Anatomie c√©r√©brale, positions d'an√©vrismes, modalit√©s d'imagerie

---

## R√©f√©rences

- **Dataset source** : [RSNA Intracranial Aneurysm Detection](https://www.kaggle.com/competitions/rsna-intracranial-aneurysm-detection)
- **Architecture** : Inspired by 3D ResNet for medical imaging
- **PyDICOM Documentation** : [https://pydicom.github.io/](https://pydicom.github.io/)
- **Medical Imaging Resources** : [RadioGraphics RSNA](https://pubs.rsna.org/journal/radiographics)

---

## Auteur

**Emma B.**

*√âtudiante en L3 Math√©matiques*
*Data Scientist autodidacte passionn√©e par le ML appliqu√© √† la sant√©*

---

## License

Ce projet est √† usage √©ducatif et de d√©monstration pour portfolio professionnel.

Les donn√©es DICOM ne sont pas incluses dans ce repository pour des raisons de confidentialit√© et de taille.
