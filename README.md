# DÃ©tection d'AnÃ©vrismes CÃ©rÃ©braux par Deep Learning ğŸ§ 

Projet de dÃ©tection automatique d'anÃ©vrismes cÃ©rÃ©braux Ã  partir d'images mÃ©dicales 3D (CTA, MRA, MRI) utilisant des rÃ©seaux de neurones convolutifs 3D.

---

## ğŸ“Š Ã€ propos de ce Repository

### Version de DÃ©monstration

Ce repository contient une **version de dÃ©monstration locale** d'un projet plus large rÃ©alisÃ© sur Kaggle.

| Aspect | Version Kaggle (Originale) | Version DÃ©monstration (ce repo) |
|--------|---------------------------|----------------------------------|
| **DonnÃ©es** | 4000+ sÃ©ries DICOM | 20 sÃ©ries Ã©chantillons |
| **Environnement** | Kaggle GPU | Local (CPU/GPU) |
| **Objectif** | EntraÃ®nement complet | DÃ©monstration & Portfolio |
| **Architecture** | Identique âœ“ | Identique âœ“ |
| **Pipeline** | Identique âœ“ | Identique âœ“ |

**But de cette version** : Permettre aux recruteurs et collaborateurs de :
- Visualiser la structure du projet et du code
- Comprendre le pipeline de preprocessing
- Voir des exemples concrets de datasets crÃ©Ã©s
- Tester le code localement sans tÃ©lÃ©charger 4000 sÃ©ries

---

## ğŸ—ï¸ Architecture du Projet

Le projet suit une **architecture modulaire brick-based** pour une rÃ©utilisabilitÃ© maximale :

```
src/
â”œâ”€â”€ bricks/              # Composants rÃ©utilisables
â”‚   â”œâ”€â”€ preprocessing.py # Pipeline de preprocessing 3D
â”‚   â””â”€â”€ dataset.py       # Construction de datasets
â”œâ”€â”€ data/                # Utilitaires de chargement DICOM
â”œâ”€â”€ preprocessing/       # Transformations (resample, crop, normalize)
â”œâ”€â”€ visualization/       # Visualisation de volumes 3D
â””â”€â”€ config.py            # Configuration centralisÃ©e
```

### Composants Principaux

**`Preprocessor`** : Pipeline de preprocessing pour volumes DICOM 3D
- Chargement DICOM
- Resampling Ã  espacement cible
- Cropping automatique
- Normalisation

**`DatasetBuilder`** : Construction de datasets d'entraÃ®nement
- Extraction de cubes 3D (positifs/nÃ©gatifs)
- One-hot encoding des positions anatomiques
- Sauvegarde au format `.npz`

---

## ğŸ“ Structure des DonnÃ©es

### ModalitÃ©s SupportÃ©es

Le projet gÃ¨re 4 modalitÃ©s d'imagerie mÃ©dicale :

| ModalitÃ© | Description | SÃ©ries (dÃ©mo) | SÃ©ries (Kaggle) |
|----------|-------------|---------------|-----------------|
| **CTA** | Angiographie par tomodensitomÃ©trie | 9 | ~1220 |
| **MRA** | Angiographie par rÃ©sonance magnÃ©tique | 3 | ~661 |
| **MRI T2** | IRM pondÃ©rÃ©e T2 | 7 | ~280 |
| **MRI T1post** | IRM T1 avec contraste | 1 | ~93 |

### Datasets CrÃ©Ã©s

Chaque modalitÃ© gÃ©nÃ¨re un fichier `.npz` contenant :

```python
{
    'cubes': np.ndarray,      # (N, 48, 48, 48) - Cubes 3D normalisÃ©s
    'labels': np.ndarray,     # (N,) - 0=nÃ©gatif, 1=positif
    'positions': np.ndarray,  # (N, 13) - One-hot encoding position anatomique
    'patient_ids': list       # (N,) - SeriesInstanceUID
}
```

**Fichiers gÃ©nÃ©rÃ©s** :
- `results/processed/cta_dataset.npz`
- `results/processed/mra_dataset.npz`
- `results/processed/mri_t2_dataset.npz`
- `results/processed/mri_t1post_dataset.npz`

---

## ğŸ““ Notebooks

| Notebook | Description | Usage |
|----------|-------------|-------|
| `01_exploration_donnees.ipynb` | Analyse exploratoire des donnÃ©es DICOM | Comprendre les donnÃ©es |
| `02_dataset_creation.ipynb` | CrÃ©ation des 4 datasets par modalitÃ© | **ExÃ©cuter en premier** |
| `03_entrainement_modele.ipynb` | EntraÃ®nement du modÃ¨le 3D CNN | AprÃ¨s crÃ©ation datasets |
| `04_inference.ipynb` | InfÃ©rence sur nouveaux patients | Tests & dÃ©monstration |

> **Note**: Les notebooks utilisent un Ã©chantillon de 20 sÃ©ries DICOM pour dÃ©monstration.
> Le projet original sur Kaggle a traitÃ© 4000+ sÃ©ries avec la mÃªme architecture.

---

## ğŸš€ Utilisation

### PrÃ©requis

```bash
pip install -r requirements.txt
```

### Configuration Automatique

Le projet dÃ©tecte automatiquement l'environnement (Kaggle vs Local) :

```python
from src import SERIES_DIR, TRAIN_CSV, PROCESSED_DIR, print_config

print_config()  # Affiche les chemins configurÃ©s
```

### CrÃ©ation des Datasets

1. **Ouvrir** `notebooks/02_dataset_creation.ipynb`
2. **ExÃ©cuter** les cellules jusqu'Ã  la section 5
3. **DÃ©commenter** le code de crÃ©ation dans les sections 5, 6, 7
4. **Lancer** la crÃ©ation des 4 datasets

Les datasets seront sauvegardÃ©s dans `results/processed/`

### Structure des RÃ©sultats

```
results/
â”œâ”€â”€ processed/           # Datasets crÃ©Ã©s (.npz)
â”œâ”€â”€ models/             # ModÃ¨les entraÃ®nÃ©s (.pth)
â””â”€â”€ checkpoints/        # Checkpoints d'entraÃ®nement
```

---

## ğŸ¯ RÃ©sultats de la DÃ©monstration

### Datasets de DÃ©monstration CrÃ©Ã©s

| ModalitÃ© | SÃ©ries | Cubes positifs | Cubes nÃ©gatifs | Balance |
|----------|--------|----------------|----------------|---------|
| CTA | 9 | ~6 | ~X | XX% |
| MRA | 3 | ~2 | ~X | XX% |
| MRI T2 | 7 | ~1 | ~X | XX% |
| MRI T1post | 1 | 0 | ~X | XX% |

*Note : Les valeurs exactes dÃ©pendent du nombre de cubes extraits par volume*

### Utilisation RecommandÃ©e

- **CTA** : Dataset principal pour dÃ©monstration (meilleure reprÃ©sentativitÃ©)
- **MRA** : Validation cross-modalitÃ©
- **MRI T2** : Tests de gÃ©nÃ©ralisation
- **MRI T1post** : Exemple de modalitÃ© rare

---

## ğŸ”§ Technologies

- **Python 3.13+**
- **PyTorch** : Deep Learning
- **PyDICOM** : Lecture fichiers DICOM
- **NumPy & SciPy** : Traitement volumÃ©trique
- **Pandas** : Manipulation de donnÃ©es
- **Matplotlib** : Visualisation

---

## ğŸ“ Notes Importantes

### Limitations de la Version DÃ©monstration

- âš ï¸ **DonnÃ©es limitÃ©es** : 20 sÃ©ries vs 4000 sur Kaggle
- âš ï¸ **Performances** : RÃ©sultats non reprÃ©sentatifs (Ã©chantillon trop petit)
- âš ï¸ **Usage** : DÃ©monstration de l'architecture uniquement

### Points Forts du Projet

- âœ… **Architecture modulaire** : Code rÃ©utilisable et maintenable
- âœ… **Multi-modalitÃ©s** : Support de 4 types d'imagerie mÃ©dicale
- âœ… **Pipeline complet** : De DICOM brut Ã  modÃ¨le entraÃ®nÃ©
- âœ… **Gestion d'erreurs** : Robuste aux donnÃ©es manquantes
- âœ… **Documentation** : Code commentÃ© et notebooks explicatifs

---

## ğŸ“š RÃ©fÃ©rences

- **Dataset source** : [RSNA Intracranial Hemorrhage Detection](https://www.kaggle.com/competitions/rsna-intracranial-hemorrhage-detection)
- **Architecture** : Inspired by 3D ResNet for medical imaging

---

## ğŸ‘¤ Auteur

**Emma B.**

*Data Scientist spÃ©cialisÃ©e en Deep Learning pour l'imagerie mÃ©dicale*

---

## ğŸ“„ License

Ce projet est Ã  usage Ã©ducatif et de dÃ©monstration pour portfolio professionnel.

Les donnÃ©es DICOM ne sont pas incluses dans ce repository pour des raisons de confidentialitÃ© et de taille.
