# Architecture du Projet - DÃ©tection d'AnÃ©vrismes

## ğŸ“ Vue d'Ensemble

Ce projet suit une architecture modulaire avec des composants de pipeline rÃ©utilisables (**bricks**), permettant une orchestration flexible et un dÃ©ploiement facile en production.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ORCHESTRATION                             â”‚
â”‚              (notebooks/00_orchestration.ipynb)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                  â–¼                  â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   EDA   â”‚       â”‚ Dataset  â”‚      â”‚ Training â”‚
   â”‚         â”‚â”€â”€â”€â”€â”€â”€â”€â”‚ Builder  â”‚â”€â”€â”€â”€â”€â”€â”‚          â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚                  â”‚
                           â–¼                  â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Augmentor   â”‚    â”‚ Predictorâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼              â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚Preprocessâ”‚  â”‚  Models  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‚ Structure du Projet

```
ANEURYSM DETECTION/
â”‚
â”œâ”€â”€ data/                           # DonnÃ©es (gitignored)
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ train_localizers.csv
â”‚   â””â”€â”€ series/                     # SÃ©ries DICOM
â”‚       â””â”€â”€ <SeriesInstanceUID>/
â”‚
â”œâ”€â”€ src/                            # Package Python
â”‚   â”œâ”€â”€ __init__.py                # Exports principaux
â”‚   â”œâ”€â”€ config.py                  # Constantes globales
â”‚   â”œâ”€â”€ paths.py                   # Gestion chemins Kaggle/local
â”‚   â”‚
â”‚   â”œâ”€â”€ bricks/                    # â­ Composants de pipeline
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ preprocessing.py       # Preprocessor
â”‚   â”‚   â”œâ”€â”€ dataset.py             # DatasetBuilder
â”‚   â”‚   â”œâ”€â”€ augmentation.py        # Augmentor
â”‚   â”‚   â”œâ”€â”€ eda.py                 # EDA
â”‚   â”‚   â”œâ”€â”€ training.py            # Trainer
â”‚   â”‚   â”œâ”€â”€ inference.py           # Predictor
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                    # Architectures de modÃ¨les
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ unet3d.py             # UNet3DClassifier
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                      # Utilitaires DICOM
â”‚   â”‚   â”œâ”€â”€ dicom_loader.py
â”‚   â”‚   â””â”€â”€ metadata.py
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/             # Fonctions bas niveau
â”‚   â”‚   â”œâ”€â”€ transforms.py
â”‚   â”‚   â”œâ”€â”€ coordinates.py
â”‚   â”‚   â””â”€â”€ pipeline.py
â”‚   â”‚
â”‚   â”œâ”€â”€ augmentation/              # DÃ©formations Ã©lastiques
â”‚   â”‚   â””â”€â”€ elastic.py
â”‚   â”‚
â”‚   â”œâ”€â”€ visualization/             # Visualisation
â”‚   â”‚   â””â”€â”€ viewers.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/                     # Utilitaires
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ notebooks/                     # Notebooks Jupyter
â”‚   â”œâ”€â”€ 00_orchestration.ipynb    # â­ Pipeline principal
â”‚   â”œâ”€â”€ 01_exploration_donnees.ipynb
â”‚   â”œâ”€â”€ 02_dataset_creation.ipynb
â”‚   â”œâ”€â”€ 03_entrainement_modele.ipynb
â”‚   â”œâ”€â”€ 04_inference.ipynb
â”‚   â”œâ”€â”€ 05_data_augmentation.ipynb
â”‚   â”œâ”€â”€ 06_gestion_erreurs.ipynb
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ results/                       # Sorties (gitignored)
â”‚   â”œâ”€â”€ processed/                # Datasets crÃ©Ã©s
â”‚   â”œâ”€â”€ models/                   # ModÃ¨les entraÃ®nÃ©s
â”‚   â””â”€â”€ checkpoints/              # Checkpoints
â”‚
â”œâ”€â”€ tests/                         # Tests unitaires (Ã  crÃ©er)
â”‚
â”œâ”€â”€ .gitignore                     # Protection donnÃ©es
â”œâ”€â”€ requirements.txt               # DÃ©pendances
â”œâ”€â”€ README.md                      # Documentation projet
â”œâ”€â”€ ARCHITECTURE.md               # Ce fichier
â”œâ”€â”€ MIGRATION_GUIDE.md            # Guide migration
â””â”€â”€ PATH_MIGRATION_COMPLETE.md    # Guide chemins

```

## ğŸ§± Composants Bricks

### 1. Preprocessor
**ResponsabilitÃ©** : Preprocessing des volumes DICOM 3D
**Input** : Chemin vers sÃ©rie DICOM
**Output** : Volume normalisÃ© (+ coordonnÃ©es transformÃ©es optionnel)
**MÃ©thodes clÃ©s** :
- `process_volume(patient_path)` â†’ volume
- `process_volume_with_coords(patient_path, coords)` â†’ volume, coords

### 2. DatasetBuilder
**ResponsabilitÃ©** : Construction de datasets d'entraÃ®nement
**Input** : DataFrames + Preprocessor
**Output** : Dataset au format dict/npz
**MÃ©thodes clÃ©s** :
- `build_dataset(df_train, df_localizers, modality)` â†’ dataset
- `save(dataset, path)` / `load(path)` â†’ dataset

### 3. Augmentor
**ResponsabilitÃ©** : Augmentation de donnÃ©es par dÃ©formations Ã©lastiques
**Input** : Dataset
**Output** : Dataset augmentÃ©
**MÃ©thodes clÃ©s** :
- `augment_dataset(dataset)` â†’ augmented_dataset
- `save(dataset, path)` / `load(path)` â†’ dataset

### 4. EDA
**ResponsabilitÃ©** : Analyse exploratoire des donnÃ©es
**Input** : DataFrames + chemin sÃ©ries
**Output** : Statistiques, visualisations, rapports
**MÃ©thodes clÃ©s** :
- `analyze_modalities()` â†’ stats
- `detect_defective_series()` â†’ liste UIDs
- `generate_report()` â†’ rapport complet

### 5. Trainer
**ResponsabilitÃ©** : EntraÃ®nement de modÃ¨les PyTorch
**Input** : ModÃ¨le + DataLoaders
**Output** : ModÃ¨le entraÃ®nÃ© + mÃ©triques
**MÃ©thodes clÃ©s** :
- `fit(train_loader, val_loader, epochs)` â†’ historique
- `save_checkpoint(path)` / `load_checkpoint(path)`
- `plot_history()` â†’ visualisation

### 6. Predictor
**ResponsabilitÃ©** : InfÃ©rence sur nouveaux volumes
**Input** : ModÃ¨le + volume
**Output** : PrÃ©diction agrÃ©gÃ©e
**MÃ©thodes clÃ©s** :
- `predict_volume(patient_path)` â†’ prediction dict
- `predict_batch(patient_paths)` â†’ liste predictions

## ğŸ”„ Flux de DonnÃ©es

### Pipeline Complet

```
1. EDA
   â”‚
   â””â”€â”€> Analyse des donnÃ©es
        - Distribution modalitÃ©s
        - SÃ©ries dÃ©fectueuses
        - Statistiques anÃ©vrismes
   â”‚
   â–¼
2. Dataset Creation
   â”‚
   â”œâ”€â”€> Preprocessor
   â”‚    - Load DICOM
   â”‚    - Resample
   â”‚    - Crop
   â”‚    - Normalize
   â”‚
   â””â”€â”€> DatasetBuilder
        - Extract positives
        - Extract negatives
        - Create labels/positions
        - Save .npz
   â”‚
   â–¼
3. Augmentation
   â”‚
   â””â”€â”€> Augmentor
        - Elastic deformations
        - N versions per cube
        - Save augmented .npz
   â”‚
   â–¼
4. Training
   â”‚
   â”œâ”€â”€> PyTorch Dataset
   â”‚    - Load .npz
   â”‚    - To tensors
   â”‚
   â”œâ”€â”€> DataLoader
   â”‚    - Batching
   â”‚    - Shuffling
   â”‚
   â””â”€â”€> Trainer
        - Train epochs
        - Validate
        - Save checkpoints
        - Track metrics
   â”‚
   â–¼
5. Inference
   â”‚
   â””â”€â”€> Predictor
        - Load model
        - Process volume
        - Aggregate predictions
        - Return results
```

## ğŸ¯ Avantages de cette Architecture

### âœ… ModularitÃ©
- Chaque composant est indÃ©pendant
- Facile Ã  tester unitairement
- RÃ©utilisable dans d'autres projets

### âœ… FlexibilitÃ©
- On peut remplacer n'importe quel composant
- Facile d'ajouter de nouvelles features
- Support de multiples modalitÃ©s

### âœ… MaintenabilitÃ©
- Code organisÃ© et documentÃ©
- ResponsabilitÃ©s claires
- Facile Ã  dÃ©bugger

### âœ… Production-Ready
- Pipeline complet dans un notebook
- Facile Ã  dÃ©ployer
- Versioning clair

### âœ… Collaboration
- Structure standard
- Documentation complÃ¨te
- Facile pour nouveaux contributeurs

## ğŸ“Š Comparaison Avant/AprÃ¨s

### Avant (Notebooks monolithiques)
```python
# Notebook 1: 500 lignes
def dicom_to_numpy(...): ...
def resample(...): ...
def crop(...): ...
# ... 20 fonctions ...
# Code d'analyse
# Code de preprocessing
# Code d'entraÃ®nement
```

**ProblÃ¨mes** :
- âŒ Duplication de code entre notebooks
- âŒ Difficile Ã  maintenir
- âŒ Pas testable
- âŒ Difficile Ã  dÃ©ployer

### AprÃ¨s (Architecture modulaire)
```python
# Notebook d'orchestration: 50 lignes
from src.bricks import Preprocessor, DatasetBuilder, Trainer

preprocessor = Preprocessor()
builder = DatasetBuilder(preprocessor)
trainer = Trainer(model, criterion, optimizer)

dataset = builder.build_dataset(df_train, df_loc, modality='CTA')
trainer.fit(train_loader, val_loader, epochs=10)
```

**Avantages** :
- âœ… Code rÃ©utilisable
- âœ… Facile Ã  maintenir
- âœ… Testable
- âœ… Production-ready

## ğŸš€ Utilisation

### Quick Start

```python
# Import tout depuis src
from src import *
from src.bricks import *
from src.models import *

# 1. EDA
eda = EDA(df_train, df_localizers, SERIES_DIR)
eda.generate_report()

# 2. Dataset
preprocessor = Preprocessor()
builder = DatasetBuilder(preprocessor, series_dir=SERIES_DIR)
dataset = builder.build_dataset(df_train, df_localizers, modality='CTA')

# 3. Augmentation
augmentor = Augmentor(n_augmentations=12)
dataset_aug = augmentor.augment_dataset(dataset)

# 4. Training
model = UNet3DClassifier()
trainer = Trainer(model, criterion, optimizer)
trainer.fit(train_loader, val_loader, epochs=10)

# 5. Inference
predictor = Predictor(model, preprocessor)
prediction = predictor.predict_volume(patient_path)
```

### Notebook d'Orchestration

Le notebook [`00_orchestration.ipynb`](notebooks/00_orchestration.ipynb) contient un pipeline complet prÃªt Ã  l'emploi.

## ğŸ§ª Tests (Ã€ ImplÃ©menter)

Structure recommandÃ©e pour les tests :

```
tests/
â”œâ”€â”€ test_preprocessing.py
â”œâ”€â”€ test_dataset.py
â”œâ”€â”€ test_augmentation.py
â”œâ”€â”€ test_eda.py
â”œâ”€â”€ test_training.py
â””â”€â”€ test_inference.py
```

## ğŸ“– Documentation

- **README.md** : Vue d'ensemble du projet
- **ARCHITECTURE.md** : Ce fichier - architecture dÃ©taillÃ©e
- **MIGRATION_GUIDE.md** : Migration de l'ancien code
- **src/bricks/README.md** : Documentation des bricks
- **notebooks/README.md** : Guide des notebooks

## ğŸ”® Ã‰volutions Futures

### Court Terme
- [ ] Tests unitaires pour chaque brick
- [ ] CI/CD avec GitHub Actions
- [ ] Notebook d'expÃ©rimentation

### Moyen Terme
- [ ] Support de nouvelles modalitÃ©s
- [ ] Hyperparameter tuning
- [ ] MLflow pour tracking

### Long Terme
- [ ] API REST pour infÃ©rence
- [ ] Interface web
- [ ] DÃ©ploiement cloud

## ğŸ“š Ressources

- [Documentation PyTorch](https://pytorch.org/docs/)
- [DICOM Standard](https://www.dicomstandard.org/)
- [UNet Paper](https://arxiv.org/abs/1505.04597)

---

**Version** : 0.2.0
**DerniÃ¨re mise Ã  jour** : 2025-12-26
