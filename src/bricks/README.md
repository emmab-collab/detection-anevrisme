# Bricks - Composants de Pipeline

Ce module contient les composants de pipeline r√©utilisables pour le projet de d√©tection d'an√©vrismes.

## Composants Disponibles

### 1. `Preprocessor` - Preprocessing des volumes

G√®re tout le preprocessing des volumes DICOM 3D :
- Chargement DICOM
- Resampling √† un espacement cible
- Cropping pour retirer le fond noir
- Normalisation entre 0 et 1
- Transformation de coordonn√©es

**Exemple** :
```python
from src.bricks import Preprocessor

preprocessor = Preprocessor(target_spacing=(0.4, 0.4, 0.4))

# Process volume seul
volume = preprocessor.process_volume(patient_path)

# Process volume avec coordonn√©es
volume, coords = preprocessor.process_volume_with_coords(patient_path, aneurysm_coords)
```

### 2. `DatasetBuilder` - Construction de datasets

Construit des datasets d'entra√Ænement √† partir de volumes DICOM :
- Extraction de cubes positifs (avec an√©vrisme)
- Extraction de cubes n√©gatifs (sans an√©vrisme)
- Cr√©ation de vecteurs one-hot pour les positions
- Sauvegarde/chargement au format .npz

**Exemple** :
```python
from src.bricks import Preprocessor, DatasetBuilder

preprocessor = Preprocessor()
builder = DatasetBuilder(preprocessor, cube_size=48, series_dir=SERIES_DIR)

# Construire dataset pour CTA
dataset = builder.build_dataset(df_train, df_localizers, modality='CTA')

# Sauvegarder
builder.save(dataset, 'results/processed/cta_dataset.npz')

# Charger
dataset = DatasetBuilder.load('results/processed/cta_dataset.npz')
```

### 3. `Augmentor` - Augmentation de donn√©es

Applique des d√©formations √©lastiques pour augmenter le dataset :
- D√©formations 3D al√©atoires
- Augmentation configurable (nombre de versions)
- Support pour augmenter seulement les positifs

**Exemple** :
```python
from src.bricks import Augmentor

augmentor = Augmentor(n_augmentations=12)

# Augmenter un dataset complet
dataset_augmented = augmentor.augment_dataset(dataset, augment_negatives=False)

# Sauvegarder
augmentor.save(dataset_augmented, 'results/processed/dataset_augmented.npz')
```

### 4. `EDA` - Analyse Exploratoire

Analyse les donn√©es DICOM :
- Distribution des modalit√©s
- Distribution des an√©vrismes
- D√©tection de s√©ries d√©fectueuses
- Statistiques sur les slices
- G√©n√©ration de rapports

**Exemple** :
```python
from src.bricks import EDA

eda = EDA(df_train, df_localizers, SERIES_DIR)

# Analyses
eda.analyze_modalities()
eda.analyze_aneurysm_distribution()
defective = eda.detect_defective_series()

# Rapport complet
eda.generate_report()

# Visualisations
eda.plot_aneurysm_distribution()
```

### 5. `Trainer` - Entra√Ænement de mod√®les

G√®re l'entra√Ænement de mod√®les PyTorch :
- Entra√Ænement par epochs
- Validation
- Sauvegarde de checkpoints
- Suivi de m√©triques
- Visualisation de l'historique

**Exemple** :
```python
from src.bricks import Trainer
from src.models import UNet3DClassifier

model = UNet3DClassifier()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

trainer = Trainer(model, criterion, optimizer, checkpoint_dir='results/checkpoints')

# Entra√Æner
trainer.fit(train_loader, val_loader, epochs=10)

# Visualiser
trainer.plot_history()

# Sauvegarder
trainer.save_checkpoint('results/models/best_model.pth')
```

### 6. `Predictor` - Inf√©rence

Effectue des pr√©dictions sur de nouveaux volumes :
- Chargement de mod√®les entra√Æn√©s
- Extraction de cubes chevauchants
- Pr√©diction par cube
- Agr√©gation de pr√©dictions (mean, max, percentile)

**Exemple** :
```python
from src.bricks import Predictor, Preprocessor
from src.models import UNet3DClassifier

model = UNet3DClassifier()
preprocessor = Preprocessor()

predictor = Predictor(model, preprocessor)
predictor.load_model('results/models/best_model.pth')

# Pr√©dire sur un volume
prediction = predictor.predict_volume(
    patient_path,
    threshold=0.5,
    top_k=5,
    aggregation='mean'
)

print(prediction)
# {'volume_prob': 0.87, 'volume_label': 1, 'n_cubes': 150, 'top_k_probs': [0.95, 0.92, ...]}
```

## üöÄ Usage - Pipeline Complet

Voir le notebook [`00_orchestration.ipynb`](../../notebooks/00_orchestration.ipynb) pour un exemple complet d'utilisation de tous les composants ensemble.

## üìÅ Structure des Fichiers

```
src/bricks/
‚îú‚îÄ‚îÄ __init__.py          # Exports des classes
‚îú‚îÄ‚îÄ preprocessing.py     # Classe Preprocessor
‚îú‚îÄ‚îÄ dataset.py           # Classe DatasetBuilder
‚îú‚îÄ‚îÄ augmentation.py      # Classe Augmentor
‚îú‚îÄ‚îÄ eda.py               # Classe EDA
‚îú‚îÄ‚îÄ training.py          # Classe Trainer
‚îú‚îÄ‚îÄ inference.py         # Classe Predictor
‚îî‚îÄ‚îÄ README.md           # Ce fichier
```

## üîß Extension

Pour ajouter un nouveau composant :

1. Cr√©er un nouveau fichier dans `src/bricks/`
2. Impl√©menter votre classe
3. L'ajouter √† `src/bricks/__init__.py`
4. L'ajouter √† `src/__init__.py`
5. Documenter dans ce README

## üí° Principes de Design

Chaque classe suit ces principes :

- **Single Responsibility** : Une classe = une responsabilit√© claire
- **Configurabilit√©** : Param√®tres dans `__init__`
- **Cha√Ænabilit√©** : Les sorties peuvent √™tre pass√©es aux entr√©es d'autres classes
- **Testabilit√©** : Code isol√© et facile √† tester
- **Documentation** : Docstrings NumPy compl√®tes

## üìö Documentation Compl√®te

Chaque classe contient des docstrings d√©taill√©es avec :
- Description
- Param√®tres
- Returns
- Exemples d'utilisation

Utilisez `help(ClassName)` ou consultez les docstrings directement dans le code.
